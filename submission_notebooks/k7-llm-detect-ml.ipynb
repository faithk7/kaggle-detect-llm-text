{"cells":[{"cell_type":"code","execution_count":50,"metadata":{},"outputs":[],"source":["import os\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import train_test_split\n","from transformers import BertTokenizer"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[],"source":["def is_kaggle_platform():\n","    return \"kaggle\" in os.listdir(\"/\")"]},{"cell_type":"code","execution_count":52,"metadata":{},"outputs":[],"source":["def get_xgboost_model():\n","    \"\"\"Get the XGBoost model\"\"\"\n","    model = xgb.XGBClassifier(objective=\"binary:logistic\", eval_metric=\"auc\")\n","    return model"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[],"source":["def get_train_data():\n","    \"\"\"Get the data\"\"\"\n","    DATA_ROOT = \"/Users/kaiqu/kaggle-datasets/llm-detect-ai-generated-text\" if not is_kaggle_platform() else \"/kaggle/input/llm-detect-ai-generated-text\"\n","    data_df = pd.read_csv(f\"{DATA_ROOT}/train_essays.csv\")\n","    # Here, replace this with actual data loading\n","    ids = data_df[\"id\"].tolist()\n","    essays = data_df[\"text\"].tolist()  # Replace with actual texts\n","    labels = data_df[\n","        \"generated\"\n","    ].tolist()  # Replace with actual labels (0 or 1)\n","    return ids, essays, labels\n","\n","# TODO: think of way to avoid such code duplication\n","def get_test_data():\n","    \"\"\"Get the test data\"\"\"\n","    DATA_ROOT = \"/Users/kaiqu/kaggle-datasets/llm-detect-ai-generated-text\" if not is_kaggle_platform() else \"/kaggle/input/llm-detect-ai-generated-text\"\n","    data_df = pd.read_csv(f\"{DATA_ROOT}/test_essays.csv\")\n","    # Here, replace this with actual data loading\n","    ids = data_df[\"id\"].tolist()\n","    essays = data_df[\"text\"].tolist()  # Replace with actual texts\n","    return ids, essays "]},{"cell_type":"code","execution_count":54,"metadata":{},"outputs":[],"source":["def tokenize_texts(essays):\n","    \"\"\"Tokenize texts using BERT tokenizer\"\"\"\n","    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","    # You may need additional preprocessing depending on your data\n","    encoded_essays = tokenizer(\n","        essays, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","    )\n","    return encoded_essays[\"input_ids\"].numpy()  # Convert to numpy array for XGBoost"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[],"source":["def train(X, y):\n","    \"\"\"Train the XGBoost model\"\"\"\n","    model = get_xgboost_model()\n","    model.fit(X, y)\n","    return model"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["X (1378, 512)\n","X_test (3, 512)\n"]}],"source":["if __name__ == \"__main__\":\n","    train_mode = False\n","    \n","    if train_mode:\n","        _, essays, labels = get_train_data()\n","\n","        # Convert essays to format suitable for XGBoost\n","        X = tokenize_texts(essays)\n","\n","        # Split data into training and test set\n","        X_train, X_test, y_train, y_test = train_test_split(\n","            X, labels, test_size=0.2, random_state=42\n","        )\n","\n","        # Train the model\n","        model = train(X_train, y_train)\n","\n","        # Evaluate the model\n","        y_pred = model.predict_proba(X_test)[:, 1]  # Get probability predictions\n","        auc_score = roc_auc_score(y_test, y_pred)\n","        print(f\"AUC Score: {auc_score}\")\n","    else:\n","        # First we train on the entire training set \n","        _, essays, labels = get_train_data()\n","        X = tokenize_texts(essays)\n","        \n","        model = train(X, labels)\n","        \n","        # Then we predict on the test set\n","        test_ids, test_essays = get_test_data()\n","        X_test = tokenize_texts(test_essays)\n","        test_y_pred = model.predict_proba(X_test)[:, 1]\n","    \n","        # Get the submission dataframe\n","        submission_df = pd.DataFrame({\"id\": test_ids, \"generated\": test_y_pred})\n","        submission_df.to_csv(\"submission.csv\", index=False)\n","    "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":2}
